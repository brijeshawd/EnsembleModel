{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "\n",
        "- LightGBM\n",
        "    - GOSS (Gradient based one side sampling)\n",
        "    - Exclusive Feature Bundling\n",
        "    - Code walkthrough\n",
        "\n",
        "- Cascading\n",
        "\n",
        "- Stacking\n",
        "\n",
        "- Comparison\n",
        "    - RF vs GBDT\n",
        "    - Cascading vs Stacking"
      ],
      "metadata": {
        "id": "baZEC2Q6DBWO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8YrMxzKbUt-"
      },
      "source": [
        "# **LightGBM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgmf4KdlbYOs"
      },
      "source": [
        "It was built at microsoft, primarily for a faster GBDT$.$\n",
        "\n",
        "It is typically faster than Xgboost because of the code optimization\n",
        "\n",
        "\n",
        "There are two main strategies for optimization:\n",
        "\n",
        "#### 1.  GOSS - Gradient based one side sampling\n",
        "\n",
        "When we are building the $m^{th}$ model the points we have is ($ x_i,res_{i,m} $),\n",
        "\n",
        "\n",
        "so here instead of considering all points \n",
        "\n",
        "- we drop the points in which the $res_{i,m}$ is small \n",
        "- i.e. smart sampling ( probability of getting large residual value is higher)\n",
        "\n",
        "So, when we are building $m^{th}$ model, we'll have fewer rows.\n",
        "\n",
        "Here the key is to reduce the number of data points due to which the model becomes faster\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj6dmciC2nX1"
      },
      "source": [
        "\n",
        "\n",
        " <img src='https://drive.google.com/uc?id=1NGKKYLSyz8MzFKQtzxnh9PTUbGQoM9JP' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp4giSc32mYW"
      },
      "source": [
        "#### 2.  Exclusive Feature Bundling (EFB)\n",
        "\n",
        "Let us assume we have a categorical feature with 3 categories \n",
        "- if we do **one hot encoding** (worst thing to do), \n",
        "    - for each row, only one of them will always be set i.e 1. \n",
        "\n",
        "<br>\n",
        "\n",
        "#### What does Exclusive feature bundling do ? (intuition not detailed)\n",
        "\n",
        "- It looks at all the dimensions \n",
        "- tries finding feature pairs s.t they are exclusive\n",
        "\n",
        "<br>\n",
        "\n",
        "#### What does exclusive mean? \n",
        "Say we have feature $f_1$, $f_2$.\n",
        "\n",
        "When we say $f_1, f_2$ are exclusive, we mean\n",
        "- if value of $f_1$ occurs, $f_2$ value doesn't\n",
        "- or if $f_1$ is high, then $f_2$ is low\n",
        "\n",
        "<br>\n",
        "\n",
        "It tries to find these exclusive features (using graph based algo) and\n",
        "- group these features \n",
        "   \n",
        "So, here the key objective of EFB is to reduce the number of features and hence reduce dimensionality "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEXawqZG3KFk"
      },
      "source": [
        " <img src='https://drive.google.com/uc?id=1G2Ilv5_nhQ0rrX0KUp60v9UoqlDApWl4' >\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLwihWKT6h3f"
      },
      "source": [
        "### Code walkthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lhDWx2x6f2_"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "#Refer: https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "import datetime as dt\n",
        "gridParams = {\n",
        "    'learning_rate': [0.1, 0.5, 0.8],\n",
        "    'boosting_type' : ['gbdt'],\n",
        "    'objective' : ['multiclass'],\n",
        "    'max_depth' : [5,6,7,8],\n",
        "    'colsample_bytree' : [0.5,0.7],\n",
        "    'subsample' : [0.5,0.7],\n",
        "    'metric':['multi_error'],\n",
        "    'random_state' : [501]\n",
        "    }\n",
        "\n",
        "clf = lgb.LGBMClassifier(num_classes=20)\n",
        "grid = RandomizedSearchCV(clf,gridParams,verbose=3,cv=3,n_jobs = -1,n_iter=10,)\n",
        "\n",
        "start = dt.datetime.now()\n",
        "grid.fit(X_train,Y_train)\n",
        "end = dt.datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85LuLTURDIDs"
      },
      "outputs": [],
      "source": [
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJJzPDtgqXoK"
      },
      "outputs": [],
      "source": [
        "best_lgbm = lgb.LGBMClassifier(boosting_typ = 'gbdt',\n",
        "                              objective = 'multiclass',\n",
        "                              num_class=20, \n",
        "                              colsample_bytree=0.7, \n",
        "                              subsample=0.7, \n",
        "                              max_depth=8, \n",
        "                              learning_rate=0.5, \n",
        "                              random_state = 501)\n",
        "best_lgbm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NStOIh5osWOa"
      },
      "outputs": [],
      "source": [
        "print(f\"Time taken for training : {end - start}\\nTraining accuracy:{best_lgbm.score(X_train, Y_train)}\\nTest Accuracy: {best_lgbm.score(X_test, Y_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kEbLJjO4qUz"
      },
      "source": [
        "Notice the time it took for 30 fits in XGBoost(5 mins) vs LightGBM (2 mins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwakB1udbnvN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS-cGrt7bns-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIJ88umwbnqS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9L__66hbnnz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tAu9F1rvmvE"
      },
      "source": [
        "# **Cascading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0QwDhMlvpQI"
      },
      "source": [
        "Lets, assume we are to detect a fraudulent transaction or not \n",
        " \n",
        "Let the dataset be $D_1$ which will be imbalanced, and \n",
        "\n",
        "- $y=1$ for fraudulent transaction\n",
        "- $y =0$ for non fraudulent transaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i14u9uSDCg9C"
      },
      "source": [
        "For a query point $x_q$, \n",
        "- we will pass this point through the first model $M_1$\n",
        "- Model $M_1$ will return the probability of the query point being a fraud\n",
        "\n",
        "\n",
        "Based on probability, we'll split it in 2 parts:\n",
        "- if the probability of $y$ being 1 is extremely low, say $< 0.001$ then \n",
        "    - we consider that as not fraudulent, let this data be $D_1'$.\n",
        "\n",
        "#### What happens to rest of the data? \n",
        "\n",
        "The rest of the points ($D_1-D_1'$) i.e. data with prob. > 0.001 which we are not sure about \n",
        "- will be passed through the next model $M_2$ \n",
        "- Model $M_2$ will be more stricter i.e. it'll penalize more.\n",
        "\n",
        "Again model $M_2$ will split into 2 parts\n",
        "- non fraud (say, $P(y =1 | x_q) < 0.001$)\n",
        "- fraud transac. (p > 0.001)\n",
        "\n",
        "We can again add another model after $M_2$ which will work on same principles\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfzVddDyS_N_"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1TwfqSCDjjS3MsXaBadxNBIvBfF9LQ0JC' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q98Cc_gUP_Vt"
      },
      "source": [
        "#### Did you notice the structure of model? \n",
        "We are cascading one model after another.\n",
        "\n",
        "In the first model we are just removing all the genuine customers\n",
        "- in second model, we are trying to find the may be fraudalent points from 2nd data set, \n",
        "\n",
        "we contimue doing this **cascading**\n",
        "\n",
        "Every model is trained on different datasets ($D_n - D_n^1$ )\n",
        "\n",
        "If even after all these models, we are not sure there will be a human at last to verify the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv0_VBKNTGS6"
      },
      "source": [
        "<img src='https://drive.google.com/uc?id=16cjT66tLCnFRuGzGPVmw4KUOgz0k85Ot' >\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO5770iPbrKh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k_YjnTSbrIh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9mG2hu_brGI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nta0NawYbrDh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvzpMEk4Uijn"
      },
      "source": [
        "# **Stacking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnAvHOerUlbj"
      },
      "source": [
        "Lets assume we have a data set of $n$ poits.\n",
        "\n",
        "#### What do we do in stacking?\n",
        "We train $m$ **individual** models (base learners) on this data set, \n",
        "- these models can be different types of models like Decision tree,  GBDT, Random forest etc.\n",
        "\n",
        "Do note that, these m model can be  optimial models.\n",
        "- i.e. perfectly fitted model with minimum CV error.\n",
        " \n",
        "Let these base learners be $c_1,c_2,....c_n$\n",
        "* Now, given a datapoint, each of these model will give a prediction ($p_1,p_2,...p_n$) \n",
        "\n",
        "Unlike RF, we we train m model and aggregate the prediction using mean/median (regression) or majority vote (classification),\n",
        "\n",
        "**In Stacking, We build a meta classifer on the predictios of the base learners**\n",
        "\n",
        "#### What model will we use as Meta classifier? \n",
        "The Meta-classifier can be any model\n",
        "* And this Meta-classifier gives the final output of the data \n",
        "\n",
        "#### What is happening in Stacking intuitively?\n",
        "Here, we are taking the outputs of the perfectly build models and stacking them together to train a Meta-classifier to get the final output\n",
        "\n",
        "BAM!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJhyoBHtWo7x"
      },
      "source": [
        " \n",
        "\n",
        "<img src='https://drive.google.com/uc?id=14Ishp1beh9iHH1TrOICRomMKRMpgRrLQ' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vO7oEQ8WTFRP"
      },
      "source": [
        "#### How is this implemented ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFNQokQaYQwn"
      },
      "source": [
        "This is implemented using the **StackingClassifier** library from **miextend.classifier** module\n",
        "* In the code we import all the libraries first\n",
        "* Then **create the base classfiers** and pass these as **inputs to stacking classfier** and use **set any model as Meta-Classifier.**\n",
        "* Now, **we train the model** and it's done\n",
        "\n",
        "Double BAM!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmaRZzoaHgU"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=17wgLrV5LKmISQw7kzLrW2rzuDiolFDM5' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA71V5rNTYtG"
      },
      "source": [
        "#### Idea looks interesting, Why don't we them ?\n",
        "Ans: coz Deep learning came into existence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dilsrxdWbsEy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOWVKk16NcHG"
      },
      "source": [
        "## Comparison\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4BNa4YOOAU"
      },
      "source": [
        "### RF vs GBDT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT2hx1lhPBp8"
      },
      "source": [
        "We use GBDT more often than RF\n",
        "\n",
        "#### Question: Why GBDT is used more often than RF?\n",
        "\n",
        "1. Because we can choose any differentiable loss function but we cannot do this for random forest \n",
        "2. Though training time varies but it's only done once so it doesnt matter much, but Run-time is important as queries are given everytime\n",
        "3. GBDT  has cheaper Run-time because \n",
        "    - the base learners are shallow and \n",
        "    - Random forest has deeper trees and \n",
        "    - the number of trees to train in GBDT are less when compared to Random Forest  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyZ70zf4R1kI"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kBqeWQ-y71bi6ndWQPUn58IGo4FmiTjT' >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Lgo3AbNfsI"
      },
      "source": [
        "# **Cascading vs Stacking**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbMPNBo2m87I"
      },
      "source": [
        "\n",
        "**Cascading** is used when the risk or cost of mistakes is high, and the data is highly imbalanced.\n",
        " * Like fraud transaction detection in amazon\n",
        "\n",
        "#### What about the explainability of the model?\n",
        "We make sure thst every model is explainable, so that we can explain the output using these models \n",
        "  * We will see few algorithms, like **LIME and SHAP** which can explain any black box algorithm after few lectures in Deep Learning.\n",
        "\n",
        "\n",
        "\n",
        "**Stacking** is mostly seen in kaggle competitions, not so much in real world."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjz5HMFAoE0b"
      },
      "source": [
        "\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1kzRryuOAFc5_HYtWcHxSGDwml-dHtGQk' >\n"
      ]
    }
  ]
}